{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Part II\n",
    "\n",
    "# C L E A N I N G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Import all required libraries and folders</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and Numpy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Regular Expression\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Read Seek scrapped data into a DataFrame</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEK_Data = pd.read_csv('Datasets/SEEK_Scrapped_Data.csv',index_col=0)\n",
    "#SEEK_Data_Other = pandas.read_csv('Datasets/SEEK_Scrapped_Data_Other.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Concatinate if multiple files and print the first 5 records</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>advertiser</th>\n",
       "      <th>date</th>\n",
       "      <th>salary</th>\n",
       "      <th>worktype</th>\n",
       "      <th>classificaiton</th>\n",
       "      <th>sub_classificaiton</th>\n",
       "      <th>city</th>\n",
       "      <th>suburb</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web Analytics Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this company</td>\n",
       "      <td>13 Feb 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Marketing &amp; Communications</td>\n",
       "      <td>Marketing &amp; Communications</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>https://www.seek.com.au/job/38337813?type=prom...</td>\n",
       "      <td>Data-Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\nGreat location in Sydney CBD - Mod...</td>\n",
       "      <td>this company</td>\n",
       "      <td>15 Feb 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>https://www.seek.com.au/job/38363396?type=stan...</td>\n",
       "      <td>Data-Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Sponsorship Available</td>\n",
       "      <td>\\r\\nAbout the business and the role\\r\\n \\r\\nMy...</td>\n",
       "      <td>this company</td>\n",
       "      <td>8 Feb 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>https://www.seek.com.au/job/38305983?type=stan...</td>\n",
       "      <td>Data-Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Head of Data Science</td>\n",
       "      <td>\\r\\nAbout our Client:  We are currently workin...</td>\n",
       "      <td>this company</td>\n",
       "      <td>16 Feb 2019</td>\n",
       "      <td>£200000.00 - £300k p.a. + super, bonus and wid...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Consulting &amp; Strategy</td>\n",
       "      <td>Consulting &amp; Strategy</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>https://www.seek.com.au/job/38366878?type=stan...</td>\n",
       "      <td>Data-Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>\\r\\n\\r\\nWork with a global leading enterprise\\...</td>\n",
       "      <td>this company</td>\n",
       "      <td>15 Feb 2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>Information &amp; Communication Technology</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>https://www.seek.com.au/job/38363660?type=stan...</td>\n",
       "      <td>Data-Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title  \\\n",
       "0                   Web Analytics Manager   \n",
       "1                 Data Science Consultant   \n",
       "2  Data Scientist - Sponsorship Available   \n",
       "3                    Head of Data Science   \n",
       "4                   Senior Data Scientist   \n",
       "\n",
       "                                         description     advertiser  \\\n",
       "0                                                NaN   this company   \n",
       "1  \\r\\n\\r\\n\\r\\nGreat location in Sydney CBD - Mod...   this company   \n",
       "2  \\r\\nAbout the business and the role\\r\\n \\r\\nMy...   this company   \n",
       "3  \\r\\nAbout our Client:  We are currently workin...   this company   \n",
       "4  \\r\\n\\r\\nWork with a global leading enterprise\\...   this company   \n",
       "\n",
       "          date                                             salary   worktype  \\\n",
       "0  13 Feb 2019                                                NaN  Full Time   \n",
       "1  15 Feb 2019                                                NaN  Full Time   \n",
       "2   8 Feb 2019                                                NaN  Full Time   \n",
       "3  16 Feb 2019  £200000.00 - £300k p.a. + super, bonus and wid...  Full Time   \n",
       "4  15 Feb 2019                                                NaN  Full Time   \n",
       "\n",
       "                           classificaiton  \\\n",
       "0              Marketing & Communications   \n",
       "1  Information & Communication Technology   \n",
       "2                    Science & Technology   \n",
       "3                   Consulting & Strategy   \n",
       "4  Information & Communication Technology   \n",
       "\n",
       "                       sub_classificaiton       city     suburb  \\\n",
       "0              Marketing & Communications  Melbourne  Melbourne   \n",
       "1  Information & Communication Technology     Sydney     Sydney   \n",
       "2                    Science & Technology     Sydney     Sydney   \n",
       "3                   Consulting & Strategy     Sydney     Sydney   \n",
       "4  Information & Communication Technology     Sydney     Sydney   \n",
       "\n",
       "                                                link      category  \n",
       "0  https://www.seek.com.au/job/38337813?type=prom...  Data-Science  \n",
       "1  https://www.seek.com.au/job/38363396?type=stan...  Data-Science  \n",
       "2  https://www.seek.com.au/job/38305983?type=stan...  Data-Science  \n",
       "3  https://www.seek.com.au/job/38366878?type=stan...  Data-Science  \n",
       "4  https://www.seek.com.au/job/38363660?type=stan...  Data-Science  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([SEEK_Data]).drop_duplicates(['description']).reset_index(drop=True)\n",
    "#df = pandas.concat([SEEK_Data,SEEK_Data_Other]).drop_duplicates(['description']).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4196, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                    0\n",
       "description              1\n",
       "advertiser              20\n",
       "date                     0\n",
       "salary                2666\n",
       "worktype                 0\n",
       "classificaiton           0\n",
       "sub_classificaiton       0\n",
       "city                     0\n",
       "suburb                   0\n",
       "link                     0\n",
       "category                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Quick SALARY Cleaning</b> \n",
    "<br>Use Regular Expression\n",
    "<br>Strip on blank and print the first 5 records\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             NaN\n",
       "1             NaN\n",
       "2             NaN\n",
       "3    200000 - 300\n",
       "4             NaN\n",
       "Name: salary, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using replace and regex to clean the salary column\n",
    "\n",
    "df[['salary']] = df[['salary']].replace('[Kk]\\b', '000', regex=True)\n",
    "df[['salary']] = df[['salary']].replace('\\.[0-9][0-9] ', ' ', regex=True)\n",
    "df[['salary']] = df[['salary']].replace('[!a-zA-Z+&,.\\$£/:)(]', '', regex=True)\n",
    "df[['salary']] = df[['salary']].replace('....%', '', regex=True)\n",
    "\n",
    "df.salary.str.strip().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               []\n",
       "1               []\n",
       "2               []\n",
       "3    [200000, 300]\n",
       "4               []\n",
       "Name: salary, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_salary(x):\n",
    "    try:\n",
    "        find = re.compile('\\d+')\n",
    "        return find.findall(x)\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "df.salary = df.salary.apply(match_salary)\n",
    "\n",
    "df.salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Convert Salary to annual salary</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         NaN\n",
       "2         NaN\n",
       "3    250000.0\n",
       "4         NaN\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def final_salary(x):\n",
    "    \n",
    "    def correct_salary(y):\n",
    "        if y == 0:\n",
    "            return np.nan\n",
    "        elif y <= 50:\n",
    "            return y * 8 * 250\n",
    "        elif y < 400 and y > 50:\n",
    "            return y * 1000\n",
    "        elif y < 2000 and y >= 500: \n",
    "            return y * 250\n",
    "        else:\n",
    "            return y\n",
    "    \n",
    "    x = [correct_salary(int(e)) for e in x]    \n",
    "    return  np.nan if len(x) == 0 else np.mean(x)\n",
    "\n",
    "df.salary = df.salary.map(lambda x: final_salary(x))\n",
    "\n",
    "df.salary = df.salary.round(0)\n",
    "\n",
    "df.salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NULL any salary less than 30K</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371       408.0\n",
      "437     27082.0\n",
      "514       425.0\n",
      "631     27373.0\n",
      "638     27373.0\n",
      "640     27373.0\n",
      "641     27373.0\n",
      "667      7665.0\n",
      "957     18000.0\n",
      "962       466.0\n",
      "1070      462.0\n",
      "1086    12000.0\n",
      "1206      425.0\n",
      "1327    10000.0\n",
      "1411    24000.0\n",
      "1538    12000.0\n",
      "1764    12000.0\n",
      "1778    12000.0\n",
      "2093     2000.0\n",
      "2190     4250.0\n",
      "2240    28000.0\n",
      "2252    27500.0\n",
      "2309    28000.0\n",
      "2562      476.0\n",
      "2633    12000.0\n",
      "2839    24000.0\n",
      "2966      425.0\n",
      "3107      450.0\n",
      "4030    10000.0\n",
      "4083    10000.0\n",
      "4086     4000.0\n",
      "Name: salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (df.loc[df.salary < 30000,'salary'])\n",
    "\n",
    "df.loc[df.salary < 30000,'salary'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.salary.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Clean DESCRIPTION</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  NaN\n",
       "1    \\r\\n\\r\\n\\r\\nGreat location in Sydney CBD - Mod...\n",
       "2    \\r\\nAbout the business and the role\\r\\n \\r\\nMy...\n",
       "3    \\r\\nAbout our Client:  We are currently workin...\n",
       "4    \\r\\n\\r\\nWork with a global leading enterprise\\...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['description']] = df[['description']].replace(['\\\\xc2', '\\\\xa0', '\\\\xe2', '\\\\x84',\n",
    "                                                   '\\\\xa2', '\\\\x80', '\\\\x93', '\\\\n',   \n",
    "                                                   '\\\\r'], ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  Nielsen is a global performance management company that provides a comprehensive understanding of what consumers Watch and Buy. Nielsen’s Watch segment provides media and advertising clients with Total Audience measurement services across all            devices where content — video, audio, and text — is consumed. The Buy segment offers consumer packaged goods manufacturers and retailers the industry’s only global view of retail performance measurement.By integrating information from            its Watch and Buy segments and other data sources, Nielsen provides its clients with both world-class measurement as well as analytics that help improve performance. Nielsen, an S&P 500 company, has operations in over 100 countries that            cover more than 90 percent of the world’s population. For more information, visit www.nielsen.com     The Opportunity     We are currently seeking a Senior Executive to join our Watch Data Science team. The Data Science organization is at the core of Nielsen’s market research methodologies. You will work amongst some highly capable professionals, giving you the chance            to absorb the ideas and perspectives of peers from a range of backgrounds. We are client-focused and deliver quality and cutting edge methods to enable Nielsen’s clients to gain valuable insights about their products and services. Data Science            supports product and methodology enhancement, new product roll-outs, sample design, universe estimation and data fusion. Data Science also ensures our survey methodologies are aligned with global standards and industry best practices.     Your key responsibilities:     Execution of universe estimation, survey weighting, data fusion and ensuring products are delivered on time and per specification  Consult with internal stakeholders and provide expert technical consultation to solve complex data science related issues  Interact with internal and external stakeholders on new methodology implementation to enhance the quality of Nielsen statistical services  Assisting with rolling out of new or enhanced services & ensure sustainability  Develop and apply technology skills to improve business processes through automation and programming tools  A full willingness to understand all of our tools and systems as well as the Nielsen product portfolio  Integration and analysis of respondent-level data from various sources       Required experience and skills:       Bachelor's degree or higher in Statistics, Mathematics, Operations Research, Computer Science, Engineering or Science discipline with outstanding analytical expertise and strong technical leadership  No less than 2 years of work experience in the survey research industry with hands on experience in developing and executing survey research methodologies  Proficient in SQL, R and/or Python  Familiar with GIT, Bitbucket, Databrick  Familiar with survey sample/panel respondent-level data  Strong statistics and data manipulation skills  General understanding and use of Nielsen products and services and/or market research techniques would be an advantage  Experience with working in a computing environment, with large datasets and able to integrate across datasets will be an advantage  Ability to use statistical methodologies to analyze data  Ability to develop quality control processes  Ability to autonomously manage simultaneous projects in a fast-paced business environment  Ability to communicate complex ideas in a simple way  High attention to detail and uses facts to support decision making  Can prioritise and allocate time effectively to meet deadlines  Comfortable working in a digitally enabled environment  A team player in a challenging and fast paced environment  Must be able to work independently and be a self-starter and self-motivated, and take initiative and ownership to get the job done       This opportunity is just the beginning of your future at Nielsen. We want you to be you - and we want to help you excel and grow in your career with us.  \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Cleaning Done copy DataFrame to a file</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/SEEK_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>CODE from Here on is NOT required only for REFERENCE</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ORIGINAL Salary Cleaning that took for ever to clean</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.salary.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# part1 = pandas.read_csv('/Users/sergi/Downloads/DSI/Project-4/Datasets/job_df_part1.csv',index_col=0)\n",
    "# #part2 = pandas.read_csv('Datasets/job_df_part2.csv',index_col=0)\n",
    "# df = pandas.concat([part1]).drop_duplicates(['description']).reset_index(drop=True)\n",
    "\n",
    "# df.salary.unique();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['new_salary']] = df[['salary']]\n",
    "df[['new_salary']] = df[['new_salary']].replace('[+]|plus','~', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('[!+&,\\/:)(]', '', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('K-|k-|K |k |K~|k~|k\\'', '000 ', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace(' to ', ' - ', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('[*\\t\\r\\n\\-]', ' ', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('per annum|p.a|annuation', '', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('%', '%%', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace(np.nan, ' ', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('#([\\w.;]+)', '', regex=True)\n",
    "#df[['new_salary']] = df[['new_salary']].replace('\\.[0-9][0-9]', '', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('[~|~]', '', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('per hour|per hr| hr|phr|Hour|hourly|Per ', 'ph', regex=True)\n",
    "df[['new_salary']] = df[['new_salary']].replace('per day|day |daily|Day', 'pd', regex=True)\n",
    "\n",
    "df[['N_salary']] = df[['new_salary']].replace(np.nan, ' ', regex=True)\n",
    "df[['Super']] = df[['salary']]\n",
    "words = ['~ super', '~ Super', 'including super', '% super', '% Super', ' super ', ' Super ', ' super', ' Super', '%super']\n",
    "hold_word = []\n",
    "new_string  = []                                               # Create empty list for store new string when reversing\n",
    "index = 0\n",
    "for string in df.new_salary[:]:                                   # Iterate thru each Salary in the file\n",
    "    new_salary = []\n",
    "    hold_string = []                                           # Create empty list to append characters\n",
    "    first_time_flag = 'Y'                                      # Set flag to be First time \n",
    "    \n",
    "    flag_1 = 'Y'\n",
    "    super_perc = []\n",
    "    hold_word = ' '\n",
    "#    print (string)\n",
    "    for word in words:\n",
    "        if word in string:\n",
    "#            print ('found\\t', word)\n",
    "            hold_word = '9.5%'\n",
    "            string = string.replace(word, '')\n",
    "#            print ('Removed word\\t', string)        \n",
    "    if '%' in string:\n",
    "        word_reverse = string[::-1]\n",
    "#        print ('Percent found', word_reverse)\n",
    "        for char in word_reverse:\n",
    "            if char == '%':\n",
    "                flag_1 = 'N'\n",
    "            if char == ' ':\n",
    "                break\n",
    "            else:\n",
    "                super_perc.insert(0,(char))\n",
    "        super_perc = ''.join(super_perc[::])\n",
    "#        print ('super_perc', super_perc, '\\t', flag_1)\n",
    "    if flag_1 == 'N':\n",
    "        hold_word = super_perc\n",
    "        string = string.replace(super_perc, '')\n",
    "#    print ('A string\\t', string, '\\thold_word\\t', hold_word, '\\tPerc\\t',super_perc)\n",
    "    df.Super[index] = hold_word\n",
    "    for char in string:                                        # iterate thru each character in the string\n",
    "        if first_time_flag == 'Y':                             # Check if First time \n",
    "            if char == '$' or char == '£' or char.isnumeric(): # when the first $,£ or numeric found  \n",
    "                first_time_flag = 'N'                          # Set flag to not be First time anymore\n",
    "        if first_time_flag == 'N':                             # If it's not first time meas it found $,£ or numeric\n",
    "            hold_string.insert(0,(char))                       # append to the new string\n",
    "            \n",
    "    if first_time_flag == 'Y':                                 # Rows with no $, £ or numerics, string is all Alpha\n",
    "        hold_string.insert(0,(' '))                            # Store a space \n",
    "        \n",
    "    hold_string = ''.join(hold_string[::-1])                   # Reverse back the new string\n",
    "    df.N_salary[index] = ''.join(hold_string[::])              # Reverse back the new string\n",
    "    index+=1\n",
    "\n",
    "# In the column 'Salary1', extract single digit in the strings\n",
    "#df[['Salary1','Salary2']] = df['N_salary'].str.split('^\\S*', expand=True)\n",
    "\n",
    "\n",
    "df.N_salary.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hold_field_1 = []\n",
    "hold_field_2 = []\n",
    "hold_field_3 = []\n",
    "for salary in df.N_salary.str.split():\n",
    "    length = (len(salary))\n",
    "#    print (salary)\n",
    "    count = 0\n",
    "    if length > 0:\n",
    "        while count <= 3 and count < length:\n",
    "            if count == 0:\n",
    "                hold_field_1.append(salary[count])\n",
    "            if count == 1:\n",
    "                hold_field_2.append(salary[count])\n",
    "            if count == 2:\n",
    "                hold_field_3.append(salary[count])\n",
    "            count +=1\n",
    "#    print (length)\n",
    "\n",
    "    if count < 4:\n",
    "        if count == 0:\n",
    "            hold_field_1.append(' ')\n",
    "            hold_field_2.append(' ')\n",
    "            hold_field_3.append(' ')\n",
    "        if count == 1:\n",
    "            hold_field_2.append(' ')\n",
    "            hold_field_3.append(' ')\n",
    "        if count == 2:\n",
    "            hold_field_3.append(' ')\n",
    "df['Salary1'] = hold_field_1\n",
    "df['Salary2'] = hold_field_2\n",
    "df['Salary3'] = hold_field_3\n",
    "\n",
    "df[['Salary1']] = df[['Salary1']].replace('\\.[0-9][0-9]', '', regex=True)\n",
    "df[['Salary1']] = df[['Salary1']].replace('[!a-zA-Z+&,.\\$£%/:)(\\']', '', regex=True) \n",
    "df[['Salary1']] = df[['Salary1']].replace(' ', np.nan, regex=True)\n",
    "#df[['Salary1']] = pd.to_numeric(df['Salary1'])\n",
    "df.Salary1 = pd.to_numeric(df.Salary1, errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Currency'] = hold_field_3          # just create a new column to overide\n",
    "pd_list = ['p.d', 'day', 'pd', 'p.d.', 'Daily', 'day ', 'p.d ', 'p.d. ', 'pd ', 'PD']\n",
    "ph_list = ['p.h', 'hour', 'ph', 'p.h.', 'Hour', 'p.h.', 'ph ', 'p.h. ', 'hr ']\n",
    "Currency_list = ['US', '£']\n",
    "\n",
    "index = 0\n",
    "for i, row in df.iterrows():\n",
    "    if df.Salary1[index] <= 20: \n",
    "        df.Salary1[index] = np.nan\n",
    "        \n",
    "    if '%' in df.Salary2[index]: \n",
    "        df.Super[index] = df.Salary2[index]\n",
    "\n",
    "    for x in pd_list:\n",
    "        if x in df.Salary2[index]:\n",
    "            df.Salary3[index] = 'pd'\n",
    "        if x in df.Salary3[index]:\n",
    "            df.Salary3[index] = 'pd'\n",
    "    for y in ph_list:\n",
    "        if y in df.Salary2[index]: \n",
    "            df.Salary3[index] = 'ph'\n",
    "        if y in df.Salary3[index]: \n",
    "            df.Salary3[index] = 'ph'\n",
    "    for z in Currency_list:\n",
    "        df.Currency[index] = ' '\n",
    "        if z in df.Salary2[index]: \n",
    "            df.Currency[index] = z\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Salary2']] = df[['Salary2']].replace('\\.[0-9][0-9]', '', regex=True)\n",
    "df[['Salary2']] = df[['Salary2']].replace('[!a-zA-Z+&,.\\$£%/:)(\\']', '', regex=True) \n",
    "df[['Salary2']] = df[['Salary2']].replace(' ', np.nan, regex=True)\n",
    "df.Salary2 = pd.to_numeric(df.Salary2, errors='coerce').fillna(0).astype(int)\n",
    "df[['Salary3']] = df[['Salary3']].replace('k|K-|k-|K |k |K~|k~|k\\'', '000 ', regex=True)\n",
    "df[['Salary3']] = df[['Salary3']].replace('[\\$£%\\']', '', regex=True) \n",
    "df[['Super']] = df[['Super']].replace('[!a-zA-Z+&,.\\$£%/:)(\\']', '', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i, row in df.iterrows():\n",
    "#    print (df.Salary3[index])\n",
    "    if 'pd' in df.Salary3[index]or 'ph' in df.Salary3[index]: \n",
    "        continue\n",
    "    else:\n",
    "        if (df.Salary3[index]).isnumeric():\n",
    "            \n",
    "            if int(df.Salary3[index]) < 50:\n",
    "                df.Salary3[index] = np.nan\n",
    "            if int(df.Salary3[index]) < 250:\n",
    "                df.Salary2[index] = int(df.Salary3[index])\n",
    "                df.Salary3[index] = 'ph'\n",
    "            else:\n",
    "                if int(df.Salary3[index]) > 249 and int(df.Salary3[index]) < 2000:\n",
    "                    df.Salary2[index] = int(df.Salary3[index])\n",
    "                    df.Salary3[index] = 'pd'\n",
    "                else:\n",
    "                    df.Salary2[index] = int(df.Salary3[index])\n",
    "                    df.Salary3[index] = ' '\n",
    "        else:   \n",
    "            df.Salary3[index] = ' '\n",
    "#         else:\n",
    "#             df.Salary3[index] = ' '\n",
    "                    \n",
    "#    print (df.Salary3[index])\n",
    "        \n",
    "    index +=1 \n",
    "df[['Salary3']] = df[['Salary3']].replace('[!a-zA-Z+&,.\\$£%/:)(\\']', '', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/job_df_clean.csv', encoding='utf8')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Salary3.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Code NOT Used which can HELP ONLY</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.Salary1:\n",
    "    print (i)\n",
    "    x = int(i)\n",
    "    if i.is_number():\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(df.Salary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "for key,value in df.iteritems():\n",
    "    print (index)\n",
    "    print (df.Salary1[index])\n",
    "    index +=1\n",
    "    \n",
    "print ('...',index)\n",
    "#    print (df.Salary1)\n",
    "#    print (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i, row in df.iterrows():\n",
    "    if df.Salary1[index] <= 20: \n",
    "        print ('Before\\t', df.Salary1[index])\n",
    "        df.Salary1[index] = np.nan\n",
    "        print ('After\\t', df.Salary1[index])\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():a\n",
    "    if row['Salary1'] > 20:            \n",
    "        print (row['Salary1'])\n",
    "    else:\n",
    "        row['Salary1'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Salary1','Salary2']] = df['N_salary'].str.split('^\\S*', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['year_quarter', 'unemployment_rate']\n",
    "df['unemployment_rate'] = df['unemployment_rate'].map(lambda x: float(str(x).replace('%','')))\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using replace and regex to clean the salary column\n",
    "\n",
    "df[['salary']] = df[['salary']].replace('[Kk]\\b', '000', regex=True)\n",
    "df[['salary']] = df[['salary']].replace('\\.[0-9][0-9] ', ' ', regex=True)\n",
    "df[['salary']] = df[['salary']].replace('[!a-zA-Z+&,.\\£/:)(]', '', regex=True)\n",
    "df[['salary']] = df[['salary']].replace('....%', '', regex=True)\n",
    "\n",
    "df.salary.str.strip().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_chars(s):\n",
    "    return ''.join(re.findall(r'\\d+[^-]+', s))\n",
    "\n",
    "def remove_chars_another(data):\n",
    "    return re.sub(\"[^0-9^.^-]\", \"\", data)\n",
    "\n",
    "def remove_dollar(data):\n",
    "    return ''.join(re.findall(r'^\\$?([0-9]{1,3},([0-9]{3},)*[0-9]{3}|[0-9]+)(.[0-9][0-9])?$', data))\n",
    "\n",
    "\\$(.*)  # grab everything after the first $ found\n",
    "([^\\s]+)  # grab fields except space - no spaces\n",
    "\n",
    "^\\S* # grab everything until first space found   \n",
    "or ([^ ]+) .*\n",
    "\n",
    "[^\\s\\s$][^\\s\\s$]{2,} just select the first numeric amount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
