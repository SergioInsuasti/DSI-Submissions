{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Sellable\n",
    "## Training with Random Forest Regressor and getting plk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# P A N D A S and N U M P Y\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# S K L E A R N\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import dill\n",
    "\n",
    "# Regular Expression\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Load Data & Create pkl file</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data to Pandas\n",
    "datafile_path = '../Datasets/OUTPUT/Combined_Output_fileComplete NSW Blacktown areas.csv'\n",
    "pickle_file_path = '../Sellable Web/RandomForest_Sellable.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Create Train and Test Data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafile_path)\n",
    "df[['Valuation']] = df[['Valuation']].replace(' ', np.nan, regex=True)\n",
    "df[['Valuation']] = df[['Valuation']].replace('[!a-zA-Z+&,.\\$£/:)(]', '', regex=True)\n",
    "df['Valuation'] = pd.to_numeric(df['Valuation'], errors='coerce').fillna(0).astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Functions</b>\n",
    "<br>&nbsp;&nbsp;&nbsp;1.&nbsp;&nbsp;&nbsp;Load data to Pandas Function\n",
    "<br>&nbsp;&nbsp;&nbsp;2.&nbsp;&nbsp;&nbsp;Basic Data Cleaning and EDA Function\n",
    "<br>&nbsp;&nbsp;&nbsp;3.&nbsp;&nbsp;&nbsp;Model fitting Function\n",
    "<br>&nbsp;&nbsp;&nbsp;4.&nbsp;&nbsp;&nbsp;Serialize Models Function\n",
    "<br>&nbsp;&nbsp;&nbsp;5.&nbsp;&nbsp;&nbsp;Main Function\n",
    "<br>&nbsp;&nbsp;&nbsp;6.&nbsp;&nbsp;&nbsp;Process\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "[     0      0      0 ... 930000      0      0]\n",
      "(2, 'No such file or directory')\n"
     ]
    }
   ],
   "source": [
    "#Load data to Pandas\n",
    "def load_data():\n",
    "    df = pd.read_csv(datafile_path)\n",
    "    df[['Valuation']] = df[['Valuation']].replace(' ', np.nan, regex=True)\n",
    "    df[['Valuation']] = df[['Valuation']].replace('[!a-zA-Z+&,.\\$£/:)(]', '', regex=True)\n",
    "    df['Valuation'] = pd.to_numeric(df['Valuation'], errors='coerce').fillna(0).astype(np.int64)\n",
    "\n",
    "#    df['Valuation'] = pd.to_numeric(df['Valuation'])\n",
    "    return df\n",
    "\n",
    "# Data Cleaning and EDA\n",
    "def EDA(df):\n",
    "#    include = ['suburb', 'Street_Name', 'bed', 'bath', 'car', 'land_sqm', 'Valuation']\n",
    "#    df = df[include].dropna()\n",
    "    include = ['suburb', 'Beds', 'Baths', 'Car', 'Lot', 'Valuation']\n",
    "    cat_list = ['suburb']\n",
    "    df = df[include].dropna()\n",
    "    df.Valuation = df.Valuation.astype(int)\n",
    "    \n",
    "    df_copy = df.copy(deep=True)\n",
    "\n",
    "# Create DUMMYS from Categorical List\n",
    "    to_drop = [n + '_' + str(df_copy[n].unique()[-1]) for n in cat_list]       # Get to_drop col names by using Categorical List\n",
    "\n",
    "    df_copy = pd.get_dummies(df_copy, columns = cat_list, drop_first = False)  # Create dummy cols into the DataFrame\n",
    "\n",
    "    for a in to_drop:                                                          # Double Check to_drop Columns\n",
    "        if(a not in df_copy.columns.values):\n",
    "            print (n)\n",
    "\n",
    "    df_copy.drop(columns = to_drop, inplace = True)                            # Drop last dummy column\n",
    "    \n",
    "    column_list = df_copy.columns.tolist()\n",
    "    df_copy = df_copy[column_list].dropna()\n",
    "    column_list.remove('Valuation')\n",
    "\n",
    "#    X = df_copy[['suburb', 'Beds', 'Baths', 'Car', 'Lot']]\n",
    "    X = df_copy[column_list]\n",
    "    y = df_copy['Valuation']\n",
    "    return (X, y)\n",
    "\n",
    "# Find Baseline\n",
    "# def baseline (y):\n",
    "#     print (y)\n",
    "#     print('Baseline accuracy:', y.value_counts(normalize=True)[1]*100)\n",
    "    \n",
    "# Model fitting\n",
    "def fit_model(X, y):\n",
    "    PREDICTOR = RandomForestClassifier(n_estimators=100).fit(X, y)\n",
    "#    PREDICTOR = RandomForestRegressor(n_estimators=100).fit(X, y)\n",
    "    print (PREDICTOR)\n",
    "    return PREDICTOR\n",
    "\n",
    "# Serialize\n",
    "def serialize(model):\n",
    "    with open(pickle_file_path, 'wb') as f:\n",
    "        dill.dump(model, f)\n",
    "\n",
    "# Main Functionf\n",
    "def main():\n",
    "    try:\n",
    "        df = load_data()\n",
    "        X, y = EDA(df)\n",
    "        model = fit_model(X, y)\n",
    "        print (model.predict(X))\n",
    "        serialize(model)\n",
    "        print ('Random Forest Classifier Trained on Sellable data and Serialized')\n",
    "    except Exception as err:\n",
    "        print(err.args)\n",
    "        exit\n",
    "\n",
    "# Process Function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
